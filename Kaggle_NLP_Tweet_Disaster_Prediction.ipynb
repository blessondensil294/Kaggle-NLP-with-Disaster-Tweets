{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle NLP Tweet Disaster Prediction.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPXaP5M5oWjQm4boLV/MJw+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blessondensil294/Kaggle-NLP-with-Disaster-Tweets/blob/master/Kaggle_NLP_Tweet_Disaster_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex5KcfxyHVf1",
        "colab_type": "text"
      },
      "source": [
        "# Real or Not? NLP with Disaster Tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JImF005nHZAk",
        "colab_type": "text"
      },
      "source": [
        "Predict which Tweets are about real disasters and which ones are not"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiXPQbkYHhrW",
        "colab_type": "text"
      },
      "source": [
        "Twitter has become an important communication channel in times of emergency.\n",
        "The ubiquitousness of smartphones enables people to announce an emergency they’re observing in real-time. Because of this, more agencies are interested in programatically monitoring Twitter (i.e. disaster relief organizations and news agencies).\n",
        "\n",
        "But, it’s not always clear whether a person’s words are actually announcing a disaster. Take this example:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The author explicitly uses the word “ABLAZE” but means it metaphorically. This is clear to a human right away, especially with the visual aid. But it’s less clear to a machine.\n",
        "\n",
        "In this competition, you’re challenged to build a machine learning model that predicts which Tweets are about real disasters and which one’s aren’t. You’ll have access to a dataset of 10,000 tweets that were hand classified. If this is your first time working on an NLP problem, we've created a quick tutorial to get you up and running.\n",
        "\n",
        "Disclaimer: The dataset for this competition contains text that may be considered profane, vulgar, or offensive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dy5JO_6OHn4J",
        "colab_type": "text"
      },
      "source": [
        "Each sample in the train and test set has the following information:\n",
        "\n",
        "The text of a tweet\n",
        "A keyword from that tweet (although this may be blank!)\n",
        "The location the tweet was sent from (may also be blank)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61TxMZfDHs-w",
        "colab_type": "text"
      },
      "source": [
        "What am I predicting?\n",
        "You are predicting whether a given tweet is about a real disaster or not. If so, predict a 1. If not, predict a 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x02tLj_6Hvl-",
        "colab_type": "text"
      },
      "source": [
        "Columns\n",
        "\n",
        "id - a unique identifier for each tweet\n",
        "\n",
        "text - the text of the tweet\n",
        "\n",
        "location - the location the tweet was sent from (may be blank)\n",
        "\n",
        "keyword - a particular keyword from the tweet (may be blank)\n",
        "\n",
        "target - in train.csv only, this denotes whether a tweet is about a real disaster (1) or not (0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASFfkobSIJNj",
        "colab_type": "text"
      },
      "source": [
        "## Loading the Data from Github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cj04tALAHdth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "df_Test_url = 'https://raw.githubusercontent.com/blessondensil294/Kaggle-NLP-with-Disaster-Tweets/master/Data/test.csv'\n",
        "df_Train_url = 'https://raw.githubusercontent.com/blessondensil294/Kaggle-NLP-with-Disaster-Tweets/master/Data/train.csv'\n",
        "df_Train = pd.read_csv(df_Train_url)\n",
        "df_Test = pd.read_csv(df_Test_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoMBYT11Inel",
        "colab_type": "text"
      },
      "source": [
        "## Load the Data for Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNxorox-IhKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_Train = pd.read_csv('../input/nlp-getting-started/train.csv')\n",
        "df_Test = pd.read_csv('../input/nlp-getting-started/test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5M7xRz-I0NZ",
        "colab_type": "text"
      },
      "source": [
        "## Exploratory Data Analysis(EDA)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw-fiVOKI_Kr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "a50a433b-fdac-47bc-9987-7731ce9a0cc2"
      },
      "source": [
        "df_Train.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-oFkGNQJBJX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "40837886-689c-4088-9220-24f95a011667"
      },
      "source": [
        "df_Train.info()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7613 entries, 0 to 7612\n",
            "Data columns (total 5 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   id        7613 non-null   int64 \n",
            " 1   keyword   7552 non-null   object\n",
            " 2   location  5080 non-null   object\n",
            " 3   text      7613 non-null   object\n",
            " 4   target    7613 non-null   int64 \n",
            "dtypes: int64(2), object(3)\n",
            "memory usage: 297.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P32WpFn1JEaq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "d40eb249-b32c-43fd-ab48-c9de2c7a7353"
      },
      "source": [
        "df_Train.columns"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'keyword', 'location', 'text', 'target'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZU1toD3dJGA1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "9cf05235-8158-47b2-e5e9-f0982bacb2ac"
      },
      "source": [
        "print('Shape of Train Data: ',df_Train.shape)\n",
        "print('Shape of Test Data: ',df_Test.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of Train Data:  (7613, 5)\n",
            "Shape of Test Data:  (3263, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2M7my0DJHq7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "692c3807-4b08-491d-d28d-961fdf735cfc"
      },
      "source": [
        "print('Null Values in Train Data: ')\n",
        "df_Train.isnull().sum()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Null Values in Train Data: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id             0\n",
              "keyword       61\n",
              "location    2533\n",
              "text           0\n",
              "target         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK0s0QayJLHq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "7fdc35aa-8676-4d76-90a8-46167a4cd637"
      },
      "source": [
        "print('Null Values in Test Data: ')\n",
        "df_Test.isnull().sum()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Null Values in Test Data: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id             0\n",
              "keyword       26\n",
              "location    1105\n",
              "text           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZvaG0OpJ_i5",
        "colab_type": "text"
      },
      "source": [
        "## Data Visualization Before Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hUuvQAcJjPH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "29587202-db10-4e0f-e435-32a7cd7e83eb"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHUvW3ItJUI8",
        "colab_type": "text"
      },
      "source": [
        "### Total Count of Target Variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2RaNzvhJYER",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "3b562ba9-47ae-42f9-d124-4ebc1a38a324"
      },
      "source": [
        "print('Total Count of the Target Variable: ')\n",
        "df_Train['target'].value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Count of the Target Variable: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvlHoQNhJb5x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "b97ff8de-c0dc-47ed-b4fd-95aacdb582a4"
      },
      "source": [
        "sns.countplot(x='target', data=df_Train)\n",
        "plt.xlabel('Target Not Disaster or Disaster')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taRNKqZ9KGkm",
        "colab_type": "text"
      },
      "source": [
        "### Word Cloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L64ConzjKLPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "\n",
        "def plot_wordcloud(text):\n",
        "    comment_words = ''\n",
        "    stopwords = set(STOPWORDS)\n",
        "    \n",
        "    for val in tweet_text:\n",
        "        val = str(val) #Convert to string\n",
        "        \n",
        "        tokens = val.split() #Split the value\n",
        "        \n",
        "        #Convert to Lowercase\n",
        "        for i in range(len(tokens)):\n",
        "            tokens[i] = tokens[i].lower()\n",
        "        \n",
        "        #Remove Unwanted Spaces\n",
        "        for words in tokens:\n",
        "            comment_words = comment_words + words + ' '\n",
        "            \n",
        "        wordcloud = WordCloud(width=5000, height=4000, background_color='white', stopwords=stopwords, min_font_size=10).generate(comment_words)\n",
        "        \n",
        "        #Plot the wordcloud image\n",
        "        plt.figure(figsize=(10,10), facecolor='k', edgecolor='k')\n",
        "        plt.imshow(wordcloud)\n",
        "        plt.axis('off')\n",
        "        plt.tight_layout(pad=0)\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6TgV4YgKTVK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "outputId": "b6adb1b3-bf9a-4bb0-f8b1-46097c403867"
      },
      "source": [
        "twitter_text = df_Train['text'].values\n",
        "#plot_wordcloud(twitter_text)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all',\n",
              "       'Forest fire near La Ronge Sask. Canada',\n",
              "       \"All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\",\n",
              "       ...,\n",
              "       'M1.94 [01:04 UTC]?5km S of Volcano Hawaii. http://t.co/zDtoyd8EbJ',\n",
              "       'Police investigating after an e-bike collided with a car in Little Portugal. E-bike rider suffered serious non-life threatening injuries.',\n",
              "       'The Latest: More Homes Razed by Northern California Wildfire - ABC News http://t.co/YmY4rSkQ3d'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-1avieVOuoY",
        "colab_type": "text"
      },
      "source": [
        "## Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OW6X1ouCRSMQ",
        "colab_type": "text"
      },
      "source": [
        "2. Clean the Text Data\n",
        "\n",
        "\t2.1 Remove or Replace common words/sentences\n",
        "\n",
        "\t2.2 Remove HTML links, Websites, Emails\n",
        "\n",
        "\t2.3 Remove Multiple Blank Space\n",
        "\n",
        "\t2.4 Convert all to Lower case\n",
        "\n",
        "\t2.5 Remove Numeric data if not relevant\n",
        "\n",
        "\t2.6 Remove Punctuations\n",
        "\n",
        "\t2.7 Remove Special Characters\n",
        "\n",
        "\t2.8 Remove Stop Words\n",
        "\n",
        "  2.9 Remove Emojis\n",
        "\n",
        "  2.10 Spell Check\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLn0sNzaqDDG",
        "colab_type": "text"
      },
      "source": [
        "### Remove/Replace Words Manually"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YthRo0vlqIaa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean(tweet): \n",
        "            \n",
        "    # Special characters\n",
        "    tweet = re.sub(r\"\\x89Û_\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89ÛÒ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89ÛÓ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89ÛÏWhen\", \"When\", tweet)\n",
        "    tweet = re.sub(r\"\\x89ÛÏ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"China\\x89Ûªs\", \"China's\", tweet)\n",
        "    tweet = re.sub(r\"let\\x89Ûªs\", \"let's\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Û÷\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Ûª\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Û\\x9d\", \"\", tweet)\n",
        "    tweet = re.sub(r\"å_\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Û¢\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Û¢åÊ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"fromåÊwounds\", \"from wounds\", tweet)\n",
        "    tweet = re.sub(r\"åÊ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"åÈ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"JapÌ_n\", \"Japan\", tweet)    \n",
        "    tweet = re.sub(r\"Ì©\", \"e\", tweet)\n",
        "    tweet = re.sub(r\"å¨\", \"\", tweet)\n",
        "    tweet = re.sub(r\"SuruÌ¤\", \"Suruc\", tweet)\n",
        "    tweet = re.sub(r\"åÇ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"å£3million\", \"3 million\", tweet)\n",
        "    tweet = re.sub(r\"åÀ\", \"\", tweet)\n",
        "    \n",
        "    # Contractions\n",
        "    tweet = re.sub(r\"he's\", \"he is\", tweet)\n",
        "    tweet = re.sub(r\"there's\", \"there is\", tweet)\n",
        "    tweet = re.sub(r\"We're\", \"We are\", tweet)\n",
        "    tweet = re.sub(r\"That's\", \"That is\", tweet)\n",
        "    tweet = re.sub(r\"won't\", \"will not\", tweet)\n",
        "    tweet = re.sub(r\"they're\", \"they are\", tweet)\n",
        "    tweet = re.sub(r\"Can't\", \"Cannot\", tweet)\n",
        "    tweet = re.sub(r\"wasn't\", \"was not\", tweet)\n",
        "    tweet = re.sub(r\"don\\x89Ûªt\", \"do not\", tweet)\n",
        "    tweet = re.sub(r\"aren't\", \"are not\", tweet)\n",
        "    tweet = re.sub(r\"isn't\", \"is not\", tweet)\n",
        "    tweet = re.sub(r\"What's\", \"What is\", tweet)\n",
        "    tweet = re.sub(r\"haven't\", \"have not\", tweet)\n",
        "    tweet = re.sub(r\"hasn't\", \"has not\", tweet)\n",
        "    tweet = re.sub(r\"There's\", \"There is\", tweet)\n",
        "    tweet = re.sub(r\"He's\", \"He is\", tweet)\n",
        "    tweet = re.sub(r\"It's\", \"It is\", tweet)\n",
        "    tweet = re.sub(r\"You're\", \"You are\", tweet)\n",
        "    tweet = re.sub(r\"I'M\", \"I am\", tweet)\n",
        "    tweet = re.sub(r\"shouldn't\", \"should not\", tweet)\n",
        "    tweet = re.sub(r\"wouldn't\", \"would not\", tweet)\n",
        "    tweet = re.sub(r\"i'm\", \"I am\", tweet)\n",
        "    tweet = re.sub(r\"I\\x89Ûªm\", \"I am\", tweet)\n",
        "    tweet = re.sub(r\"I'm\", \"I am\", tweet)\n",
        "    tweet = re.sub(r\"Isn't\", \"is not\", tweet)\n",
        "    tweet = re.sub(r\"Here's\", \"Here is\", tweet)\n",
        "    tweet = re.sub(r\"you've\", \"you have\", tweet)\n",
        "    tweet = re.sub(r\"you\\x89Ûªve\", \"you have\", tweet)\n",
        "    tweet = re.sub(r\"we're\", \"we are\", tweet)\n",
        "    tweet = re.sub(r\"what's\", \"what is\", tweet)\n",
        "    tweet = re.sub(r\"couldn't\", \"could not\", tweet)\n",
        "    tweet = re.sub(r\"we've\", \"we have\", tweet)\n",
        "    tweet = re.sub(r\"it\\x89Ûªs\", \"it is\", tweet)\n",
        "    tweet = re.sub(r\"doesn\\x89Ûªt\", \"does not\", tweet)\n",
        "    tweet = re.sub(r\"It\\x89Ûªs\", \"It is\", tweet)\n",
        "    tweet = re.sub(r\"Here\\x89Ûªs\", \"Here is\", tweet)\n",
        "    tweet = re.sub(r\"who's\", \"who is\", tweet)\n",
        "    tweet = re.sub(r\"I\\x89Ûªve\", \"I have\", tweet)\n",
        "    tweet = re.sub(r\"y'all\", \"you all\", tweet)\n",
        "    tweet = re.sub(r\"can\\x89Ûªt\", \"cannot\", tweet)\n",
        "    tweet = re.sub(r\"would've\", \"would have\", tweet)\n",
        "    tweet = re.sub(r\"it'll\", \"it will\", tweet)\n",
        "    tweet = re.sub(r\"we'll\", \"we will\", tweet)\n",
        "    tweet = re.sub(r\"wouldn\\x89Ûªt\", \"would not\", tweet)\n",
        "    tweet = re.sub(r\"We've\", \"We have\", tweet)\n",
        "    tweet = re.sub(r\"he'll\", \"he will\", tweet)\n",
        "    tweet = re.sub(r\"Y'all\", \"You all\", tweet)\n",
        "    tweet = re.sub(r\"Weren't\", \"Were not\", tweet)\n",
        "    tweet = re.sub(r\"Didn't\", \"Did not\", tweet)\n",
        "    tweet = re.sub(r\"they'll\", \"they will\", tweet)\n",
        "    tweet = re.sub(r\"they'd\", \"they would\", tweet)\n",
        "    tweet = re.sub(r\"DON'T\", \"DO NOT\", tweet)\n",
        "    tweet = re.sub(r\"That\\x89Ûªs\", \"That is\", tweet)\n",
        "    tweet = re.sub(r\"they've\", \"they have\", tweet)\n",
        "    tweet = re.sub(r\"i'd\", \"I would\", tweet)\n",
        "    tweet = re.sub(r\"should've\", \"should have\", tweet)\n",
        "    tweet = re.sub(r\"You\\x89Ûªre\", \"You are\", tweet)\n",
        "    tweet = re.sub(r\"where's\", \"where is\", tweet)\n",
        "    tweet = re.sub(r\"Don\\x89Ûªt\", \"Do not\", tweet)\n",
        "    tweet = re.sub(r\"we'd\", \"we would\", tweet)\n",
        "    tweet = re.sub(r\"i'll\", \"I will\", tweet)\n",
        "    tweet = re.sub(r\"weren't\", \"were not\", tweet)\n",
        "    tweet = re.sub(r\"They're\", \"They are\", tweet)\n",
        "    tweet = re.sub(r\"Can\\x89Ûªt\", \"Cannot\", tweet)\n",
        "    tweet = re.sub(r\"you\\x89Ûªll\", \"you will\", tweet)\n",
        "    tweet = re.sub(r\"I\\x89Ûªd\", \"I would\", tweet)\n",
        "    tweet = re.sub(r\"let's\", \"let us\", tweet)\n",
        "    tweet = re.sub(r\"it's\", \"it is\", tweet)\n",
        "    tweet = re.sub(r\"can't\", \"cannot\", tweet)\n",
        "    tweet = re.sub(r\"don't\", \"do not\", tweet)\n",
        "    tweet = re.sub(r\"you're\", \"you are\", tweet)\n",
        "    tweet = re.sub(r\"i've\", \"I have\", tweet)\n",
        "    tweet = re.sub(r\"that's\", \"that is\", tweet)\n",
        "    tweet = re.sub(r\"i'll\", \"I will\", tweet)\n",
        "    tweet = re.sub(r\"doesn't\", \"does not\", tweet)\n",
        "    tweet = re.sub(r\"i'd\", \"I would\", tweet)\n",
        "    tweet = re.sub(r\"didn't\", \"did not\", tweet)\n",
        "    tweet = re.sub(r\"ain't\", \"am not\", tweet)\n",
        "    tweet = re.sub(r\"you'll\", \"you will\", tweet)\n",
        "    tweet = re.sub(r\"I've\", \"I have\", tweet)\n",
        "    tweet = re.sub(r\"Don't\", \"do not\", tweet)\n",
        "    tweet = re.sub(r\"I'll\", \"I will\", tweet)\n",
        "    tweet = re.sub(r\"I'd\", \"I would\", tweet)\n",
        "    tweet = re.sub(r\"Let's\", \"Let us\", tweet)\n",
        "    tweet = re.sub(r\"you'd\", \"You would\", tweet)\n",
        "    tweet = re.sub(r\"It's\", \"It is\", tweet)\n",
        "    tweet = re.sub(r\"Ain't\", \"am not\", tweet)\n",
        "    tweet = re.sub(r\"Haven't\", \"Have not\", tweet)\n",
        "    tweet = re.sub(r\"Could've\", \"Could have\", tweet)\n",
        "    tweet = re.sub(r\"youve\", \"you have\", tweet)  \n",
        "    tweet = re.sub(r\"donå«t\", \"do not\", tweet)   \n",
        "            \n",
        "    # Character entity references\n",
        "    tweet = re.sub(r\"&gt;\", \">\", tweet)\n",
        "    tweet = re.sub(r\"&lt;\", \"<\", tweet)\n",
        "    tweet = re.sub(r\"&amp;\", \"&\", tweet)\n",
        "    \n",
        "    # Typos, slang and informal abbreviations\n",
        "    tweet = re.sub(r\"w/e\", \"whatever\", tweet)\n",
        "    tweet = re.sub(r\"w/\", \"with\", tweet)\n",
        "    tweet = re.sub(r\"USAgov\", \"USA government\", tweet)\n",
        "    tweet = re.sub(r\"recentlu\", \"recently\", tweet)\n",
        "    tweet = re.sub(r\"Ph0tos\", \"Photos\", tweet)\n",
        "    tweet = re.sub(r\"amirite\", \"am I right\", tweet)\n",
        "    tweet = re.sub(r\"exp0sed\", \"exposed\", tweet)\n",
        "    tweet = re.sub(r\"<3\", \"love\", tweet)\n",
        "    tweet = re.sub(r\"amageddon\", \"armageddon\", tweet)\n",
        "    tweet = re.sub(r\"Trfc\", \"Traffic\", tweet)\n",
        "    tweet = re.sub(r\"8/5/2015\", \"2015-08-05\", tweet)\n",
        "    tweet = re.sub(r\"WindStorm\", \"Wind Storm\", tweet)\n",
        "    tweet = re.sub(r\"8/6/2015\", \"2015-08-06\", tweet)\n",
        "    tweet = re.sub(r\"10:38PM\", \"10:38 PM\", tweet)\n",
        "    tweet = re.sub(r\"10:30pm\", \"10:30 PM\", tweet)\n",
        "    tweet = re.sub(r\"16yr\", \"16 year\", tweet)\n",
        "    tweet = re.sub(r\"lmao\", \"laughing my ass off\", tweet)   \n",
        "    tweet = re.sub(r\"TRAUMATISED\", \"traumatized\", tweet)\n",
        "    \n",
        "    # Hashtags and usernames\n",
        "    tweet = re.sub(r\"IranDeal\", \"Iran Deal\", tweet)\n",
        "    tweet = re.sub(r\"ArianaGrande\", \"Ariana Grande\", tweet)\n",
        "    tweet = re.sub(r\"camilacabello97\", \"camila cabello\", tweet) \n",
        "    tweet = re.sub(r\"RondaRousey\", \"Ronda Rousey\", tweet)     \n",
        "    tweet = re.sub(r\"MTVHottest\", \"MTV Hottest\", tweet)\n",
        "    tweet = re.sub(r\"TrapMusic\", \"Trap Music\", tweet)\n",
        "    tweet = re.sub(r\"ProphetMuhammad\", \"Prophet Muhammad\", tweet)\n",
        "    tweet = re.sub(r\"PantherAttack\", \"Panther Attack\", tweet)\n",
        "    tweet = re.sub(r\"StrategicPatience\", \"Strategic Patience\", tweet)\n",
        "    tweet = re.sub(r\"socialnews\", \"social news\", tweet)\n",
        "    tweet = re.sub(r\"NASAHurricane\", \"NASA Hurricane\", tweet)\n",
        "    tweet = re.sub(r\"onlinecommunities\", \"online communities\", tweet)\n",
        "    tweet = re.sub(r\"humanconsumption\", \"human consumption\", tweet)\n",
        "    tweet = re.sub(r\"Typhoon-Devastated\", \"Typhoon Devastated\", tweet)\n",
        "    tweet = re.sub(r\"Meat-Loving\", \"Meat Loving\", tweet)\n",
        "    tweet = re.sub(r\"facialabuse\", \"facial abuse\", tweet)\n",
        "    tweet = re.sub(r\"LakeCounty\", \"Lake County\", tweet)\n",
        "    tweet = re.sub(r\"BeingAuthor\", \"Being Author\", tweet)\n",
        "    tweet = re.sub(r\"withheavenly\", \"with heavenly\", tweet)\n",
        "    tweet = re.sub(r\"thankU\", \"thank you\", tweet)\n",
        "    tweet = re.sub(r\"iTunesMusic\", \"iTunes Music\", tweet)\n",
        "    tweet = re.sub(r\"OffensiveContent\", \"Offensive Content\", tweet)\n",
        "    tweet = re.sub(r\"WorstSummerJob\", \"Worst Summer Job\", tweet)\n",
        "    tweet = re.sub(r\"HarryBeCareful\", \"Harry Be Careful\", tweet)\n",
        "    tweet = re.sub(r\"NASASolarSystem\", \"NASA Solar System\", tweet)\n",
        "    tweet = re.sub(r\"animalrescue\", \"animal rescue\", tweet)\n",
        "    tweet = re.sub(r\"KurtSchlichter\", \"Kurt Schlichter\", tweet)\n",
        "    tweet = re.sub(r\"aRmageddon\", \"armageddon\", tweet)\n",
        "    tweet = re.sub(r\"Throwingknifes\", \"Throwing knives\", tweet)\n",
        "    tweet = re.sub(r\"GodsLove\", \"God's Love\", tweet)\n",
        "    tweet = re.sub(r\"bookboost\", \"book boost\", tweet)\n",
        "    tweet = re.sub(r\"ibooklove\", \"I book love\", tweet)\n",
        "    tweet = re.sub(r\"NestleIndia\", \"Nestle India\", tweet)\n",
        "    tweet = re.sub(r\"realDonaldTrump\", \"Donald Trump\", tweet)\n",
        "    tweet = re.sub(r\"DavidVonderhaar\", \"David Vonderhaar\", tweet)\n",
        "    tweet = re.sub(r\"CecilTheLion\", \"Cecil The Lion\", tweet)\n",
        "    tweet = re.sub(r\"weathernetwork\", \"weather network\", tweet)\n",
        "    tweet = re.sub(r\"withBioterrorism&use\", \"with Bioterrorism & use\", tweet)\n",
        "    tweet = re.sub(r\"Hostage&2\", \"Hostage & 2\", tweet)\n",
        "    tweet = re.sub(r\"GOPDebate\", \"GOP Debate\", tweet)\n",
        "    tweet = re.sub(r\"RickPerry\", \"Rick Perry\", tweet)\n",
        "    tweet = re.sub(r\"frontpage\", \"front page\", tweet)\n",
        "    tweet = re.sub(r\"NewsInTweets\", \"News In Tweets\", tweet)\n",
        "    tweet = re.sub(r\"ViralSpell\", \"Viral Spell\", tweet)\n",
        "    tweet = re.sub(r\"til_now\", \"until now\", tweet)\n",
        "    tweet = re.sub(r\"volcanoinRussia\", \"volcano in Russia\", tweet)\n",
        "    tweet = re.sub(r\"ZippedNews\", \"Zipped News\", tweet)\n",
        "    tweet = re.sub(r\"MicheleBachman\", \"Michele Bachman\", tweet)\n",
        "    tweet = re.sub(r\"53inch\", \"53 inch\", tweet)\n",
        "    tweet = re.sub(r\"KerrickTrial\", \"Kerrick Trial\", tweet)\n",
        "    tweet = re.sub(r\"abstorm\", \"Alberta Storm\", tweet)\n",
        "    tweet = re.sub(r\"Beyhive\", \"Beyonce hive\", tweet)\n",
        "    tweet = re.sub(r\"IDFire\", \"Idaho Fire\", tweet)\n",
        "    tweet = re.sub(r\"DETECTADO\", \"Detected\", tweet)\n",
        "    tweet = re.sub(r\"RockyFire\", \"Rocky Fire\", tweet)\n",
        "    tweet = re.sub(r\"Listen/Buy\", \"Listen / Buy\", tweet)\n",
        "    tweet = re.sub(r\"NickCannon\", \"Nick Cannon\", tweet)\n",
        "    tweet = re.sub(r\"FaroeIslands\", \"Faroe Islands\", tweet)\n",
        "    tweet = re.sub(r\"yycstorm\", \"Calgary Storm\", tweet)\n",
        "    tweet = re.sub(r\"IDPs:\", \"Internally Displaced People :\", tweet)\n",
        "    tweet = re.sub(r\"ArtistsUnited\", \"Artists United\", tweet)\n",
        "    tweet = re.sub(r\"ClaytonBryant\", \"Clayton Bryant\", tweet)\n",
        "    tweet = re.sub(r\"jimmyfallon\", \"jimmy fallon\", tweet)\n",
        "    tweet = re.sub(r\"justinbieber\", \"justin bieber\", tweet)  \n",
        "    tweet = re.sub(r\"UTC2015\", \"UTC 2015\", tweet)\n",
        "    tweet = re.sub(r\"Time2015\", \"Time 2015\", tweet)\n",
        "    tweet = re.sub(r\"djicemoon\", \"dj icemoon\", tweet)\n",
        "    tweet = re.sub(r\"LivingSafely\", \"Living Safely\", tweet)\n",
        "    tweet = re.sub(r\"FIFA16\", \"Fifa 2016\", tweet)\n",
        "    tweet = re.sub(r\"thisiswhywecanthavenicethings\", \"this is why we cannot have nice things\", tweet)\n",
        "    tweet = re.sub(r\"bbcnews\", \"bbc news\", tweet)\n",
        "    tweet = re.sub(r\"UndergroundRailraod\", \"Underground Railraod\", tweet)\n",
        "    tweet = re.sub(r\"c4news\", \"c4 news\", tweet)\n",
        "    tweet = re.sub(r\"OBLITERATION\", \"obliteration\", tweet)\n",
        "    tweet = re.sub(r\"MUDSLIDE\", \"mudslide\", tweet)\n",
        "    tweet = re.sub(r\"NoSurrender\", \"No Surrender\", tweet)\n",
        "    tweet = re.sub(r\"NotExplained\", \"Not Explained\", tweet)\n",
        "    tweet = re.sub(r\"greatbritishbakeoff\", \"great british bake off\", tweet)\n",
        "    tweet = re.sub(r\"LondonFire\", \"London Fire\", tweet)\n",
        "    tweet = re.sub(r\"KOTAWeather\", \"KOTA Weather\", tweet)\n",
        "    tweet = re.sub(r\"LuchaUnderground\", \"Lucha Underground\", tweet)\n",
        "    tweet = re.sub(r\"KOIN6News\", \"KOIN 6 News\", tweet)\n",
        "    tweet = re.sub(r\"LiveOnK2\", \"Live On K2\", tweet)\n",
        "    tweet = re.sub(r\"9NewsGoldCoast\", \"9 News Gold Coast\", tweet)\n",
        "    tweet = re.sub(r\"nikeplus\", \"nike plus\", tweet)\n",
        "    tweet = re.sub(r\"david_cameron\", \"David Cameron\", tweet)\n",
        "    tweet = re.sub(r\"peterjukes\", \"Peter Jukes\", tweet)\n",
        "    tweet = re.sub(r\"JamesMelville\", \"James Melville\", tweet)\n",
        "    tweet = re.sub(r\"megynkelly\", \"Megyn Kelly\", tweet)\n",
        "    tweet = re.sub(r\"cnewslive\", \"C News Live\", tweet)\n",
        "    tweet = re.sub(r\"JamaicaObserver\", \"Jamaica Observer\", tweet)\n",
        "    tweet = re.sub(r\"TweetLikeItsSeptember11th2001\", \"Tweet like it is september 11th 2001\", tweet)\n",
        "    tweet = re.sub(r\"cbplawyers\", \"cbp lawyers\", tweet)\n",
        "    tweet = re.sub(r\"fewmoretweets\", \"few more tweets\", tweet)\n",
        "    tweet = re.sub(r\"BlackLivesMatter\", \"Black Lives Matter\", tweet)\n",
        "    tweet = re.sub(r\"cjoyner\", \"Chris Joyner\", tweet)\n",
        "    tweet = re.sub(r\"ENGvAUS\", \"England vs Australia\", tweet)\n",
        "    tweet = re.sub(r\"ScottWalker\", \"Scott Walker\", tweet)\n",
        "    tweet = re.sub(r\"MikeParrActor\", \"Michael Parr\", tweet)\n",
        "    tweet = re.sub(r\"4PlayThursdays\", \"Foreplay Thursdays\", tweet)\n",
        "    tweet = re.sub(r\"TGF2015\", \"Tontitown Grape Festival\", tweet)\n",
        "    tweet = re.sub(r\"realmandyrain\", \"Mandy Rain\", tweet)\n",
        "    tweet = re.sub(r\"GraysonDolan\", \"Grayson Dolan\", tweet)\n",
        "    tweet = re.sub(r\"ApolloBrown\", \"Apollo Brown\", tweet)\n",
        "    tweet = re.sub(r\"saddlebrooke\", \"Saddlebrooke\", tweet)\n",
        "    tweet = re.sub(r\"TontitownGrape\", \"Tontitown Grape\", tweet)\n",
        "    tweet = re.sub(r\"AbbsWinston\", \"Abbs Winston\", tweet)\n",
        "    tweet = re.sub(r\"ShaunKing\", \"Shaun King\", tweet)\n",
        "    tweet = re.sub(r\"MeekMill\", \"Meek Mill\", tweet)\n",
        "    tweet = re.sub(r\"TornadoGiveaway\", \"Tornado Giveaway\", tweet)\n",
        "    tweet = re.sub(r\"GRupdates\", \"GR updates\", tweet)\n",
        "    tweet = re.sub(r\"SouthDowns\", \"South Downs\", tweet)\n",
        "    tweet = re.sub(r\"braininjury\", \"brain injury\", tweet)\n",
        "    tweet = re.sub(r\"auspol\", \"Australian politics\", tweet)\n",
        "    tweet = re.sub(r\"PlannedParenthood\", \"Planned Parenthood\", tweet)\n",
        "    tweet = re.sub(r\"calgaryweather\", \"Calgary Weather\", tweet)\n",
        "    tweet = re.sub(r\"weallheartonedirection\", \"we all heart one direction\", tweet)\n",
        "    tweet = re.sub(r\"edsheeran\", \"Ed Sheeran\", tweet)\n",
        "    tweet = re.sub(r\"TrueHeroes\", \"True Heroes\", tweet)\n",
        "    tweet = re.sub(r\"S3XLEAK\", \"sex leak\", tweet)\n",
        "    tweet = re.sub(r\"ComplexMag\", \"Complex Magazine\", tweet)\n",
        "    tweet = re.sub(r\"TheAdvocateMag\", \"The Advocate Magazine\", tweet)\n",
        "    tweet = re.sub(r\"CityofCalgary\", \"City of Calgary\", tweet)\n",
        "    tweet = re.sub(r\"EbolaOutbreak\", \"Ebola Outbreak\", tweet)\n",
        "    tweet = re.sub(r\"SummerFate\", \"Summer Fate\", tweet)\n",
        "    tweet = re.sub(r\"RAmag\", \"Royal Academy Magazine\", tweet)\n",
        "    tweet = re.sub(r\"offers2go\", \"offers to go\", tweet)\n",
        "    tweet = re.sub(r\"foodscare\", \"food scare\", tweet)\n",
        "    tweet = re.sub(r\"MNPDNashville\", \"Metropolitan Nashville Police Department\", tweet)\n",
        "    tweet = re.sub(r\"TfLBusAlerts\", \"TfL Bus Alerts\", tweet)\n",
        "    tweet = re.sub(r\"GamerGate\", \"Gamer Gate\", tweet)\n",
        "    tweet = re.sub(r\"IHHen\", \"Humanitarian Relief\", tweet)\n",
        "    tweet = re.sub(r\"spinningbot\", \"spinning bot\", tweet)\n",
        "    tweet = re.sub(r\"ModiMinistry\", \"Modi Ministry\", tweet)\n",
        "    tweet = re.sub(r\"TAXIWAYS\", \"taxi ways\", tweet)\n",
        "    tweet = re.sub(r\"Calum5SOS\", \"Calum Hood\", tweet)\n",
        "    tweet = re.sub(r\"po_st\", \"po.st\", tweet)\n",
        "    tweet = re.sub(r\"scoopit\", \"scoop.it\", tweet)\n",
        "    tweet = re.sub(r\"UltimaLucha\", \"Ultima Lucha\", tweet)\n",
        "    tweet = re.sub(r\"JonathanFerrell\", \"Jonathan Ferrell\", tweet)\n",
        "    tweet = re.sub(r\"aria_ahrary\", \"Aria Ahrary\", tweet)\n",
        "    tweet = re.sub(r\"rapidcity\", \"Rapid City\", tweet)\n",
        "    tweet = re.sub(r\"OutBid\", \"outbid\", tweet)\n",
        "    tweet = re.sub(r\"lavenderpoetrycafe\", \"lavender poetry cafe\", tweet)\n",
        "    tweet = re.sub(r\"EudryLantiqua\", \"Eudry Lantiqua\", tweet)\n",
        "    tweet = re.sub(r\"15PM\", \"15 PM\", tweet)\n",
        "    tweet = re.sub(r\"OriginalFunko\", \"Funko\", tweet)\n",
        "    tweet = re.sub(r\"rightwaystan\", \"Richard Tan\", tweet)\n",
        "    tweet = re.sub(r\"CindyNoonan\", \"Cindy Noonan\", tweet)\n",
        "    tweet = re.sub(r\"RT_America\", \"RT America\", tweet)\n",
        "    tweet = re.sub(r\"narendramodi\", \"Narendra Modi\", tweet)\n",
        "    tweet = re.sub(r\"BakeOffFriends\", \"Bake Off Friends\", tweet)\n",
        "    tweet = re.sub(r\"TeamHendrick\", \"Hendrick Motorsports\", tweet)\n",
        "    tweet = re.sub(r\"alexbelloli\", \"Alex Belloli\", tweet)\n",
        "    tweet = re.sub(r\"itsjustinstuart\", \"Justin Stuart\", tweet)\n",
        "    tweet = re.sub(r\"gunsense\", \"gun sense\", tweet)\n",
        "    tweet = re.sub(r\"DebateQuestionsWeWantToHear\", \"debate questions we want to hear\", tweet)\n",
        "    tweet = re.sub(r\"RoyalCarribean\", \"Royal Carribean\", tweet)\n",
        "    tweet = re.sub(r\"samanthaturne19\", \"Samantha Turner\", tweet)\n",
        "    tweet = re.sub(r\"JonVoyage\", \"Jon Stewart\", tweet)\n",
        "    tweet = re.sub(r\"renew911health\", \"renew 911 health\", tweet)\n",
        "    tweet = re.sub(r\"SuryaRay\", \"Surya Ray\", tweet)\n",
        "    tweet = re.sub(r\"pattonoswalt\", \"Patton Oswalt\", tweet)\n",
        "    tweet = re.sub(r\"minhazmerchant\", \"Minhaz Merchant\", tweet)\n",
        "    tweet = re.sub(r\"TLVFaces\", \"Israel Diaspora Coalition\", tweet)\n",
        "    tweet = re.sub(r\"pmarca\", \"Marc Andreessen\", tweet)\n",
        "    tweet = re.sub(r\"pdx911\", \"Portland Police\", tweet)\n",
        "    tweet = re.sub(r\"jamaicaplain\", \"Jamaica Plain\", tweet)\n",
        "    tweet = re.sub(r\"Japton\", \"Arkansas\", tweet)\n",
        "    tweet = re.sub(r\"RouteComplex\", \"Route Complex\", tweet)\n",
        "    tweet = re.sub(r\"INSubcontinent\", \"Indian Subcontinent\", tweet)\n",
        "    tweet = re.sub(r\"NJTurnpike\", \"New Jersey Turnpike\", tweet)\n",
        "    tweet = re.sub(r\"Politifiact\", \"PolitiFact\", tweet)\n",
        "    tweet = re.sub(r\"Hiroshima70\", \"Hiroshima\", tweet)\n",
        "    tweet = re.sub(r\"GMMBC\", \"Greater Mt Moriah Baptist Church\", tweet)\n",
        "    tweet = re.sub(r\"versethe\", \"verse the\", tweet)\n",
        "    tweet = re.sub(r\"TubeStrike\", \"Tube Strike\", tweet)\n",
        "    tweet = re.sub(r\"MissionHills\", \"Mission Hills\", tweet)\n",
        "    tweet = re.sub(r\"ProtectDenaliWolves\", \"Protect Denali Wolves\", tweet)\n",
        "    tweet = re.sub(r\"NANKANA\", \"Nankana\", tweet)\n",
        "    tweet = re.sub(r\"SAHIB\", \"Sahib\", tweet)\n",
        "    tweet = re.sub(r\"PAKPATTAN\", \"Pakpattan\", tweet)\n",
        "    tweet = re.sub(r\"Newz_Sacramento\", \"News Sacramento\", tweet)\n",
        "    tweet = re.sub(r\"gofundme\", \"go fund me\", tweet)\n",
        "    tweet = re.sub(r\"pmharper\", \"Stephen Harper\", tweet)\n",
        "    tweet = re.sub(r\"IvanBerroa\", \"Ivan Berroa\", tweet)\n",
        "    tweet = re.sub(r\"LosDelSonido\", \"Los Del Sonido\", tweet)\n",
        "    tweet = re.sub(r\"bancodeseries\", \"banco de series\", tweet)\n",
        "    tweet = re.sub(r\"timkaine\", \"Tim Kaine\", tweet)\n",
        "    tweet = re.sub(r\"IdentityTheft\", \"Identity Theft\", tweet)\n",
        "    tweet = re.sub(r\"AllLivesMatter\", \"All Lives Matter\", tweet)\n",
        "    tweet = re.sub(r\"mishacollins\", \"Misha Collins\", tweet)\n",
        "    tweet = re.sub(r\"BillNeelyNBC\", \"Bill Neely\", tweet)\n",
        "    tweet = re.sub(r\"BeClearOnCancer\", \"be clear on cancer\", tweet)\n",
        "    tweet = re.sub(r\"Kowing\", \"Knowing\", tweet)\n",
        "    tweet = re.sub(r\"ScreamQueens\", \"Scream Queens\", tweet)\n",
        "    tweet = re.sub(r\"AskCharley\", \"Ask Charley\", tweet)\n",
        "    tweet = re.sub(r\"BlizzHeroes\", \"Heroes of the Storm\", tweet)\n",
        "    tweet = re.sub(r\"BradleyBrad47\", \"Bradley Brad\", tweet)\n",
        "    tweet = re.sub(r\"HannaPH\", \"Typhoon Hanna\", tweet)\n",
        "    tweet = re.sub(r\"meinlcymbals\", \"MEINL Cymbals\", tweet)\n",
        "    tweet = re.sub(r\"Ptbo\", \"Peterborough\", tweet)\n",
        "    tweet = re.sub(r\"cnnbrk\", \"CNN Breaking News\", tweet)\n",
        "    tweet = re.sub(r\"IndianNews\", \"Indian News\", tweet)\n",
        "    tweet = re.sub(r\"savebees\", \"save bees\", tweet)\n",
        "    tweet = re.sub(r\"GreenHarvard\", \"Green Harvard\", tweet)\n",
        "    tweet = re.sub(r\"StandwithPP\", \"Stand with planned parenthood\", tweet)\n",
        "    tweet = re.sub(r\"hermancranston\", \"Herman Cranston\", tweet)\n",
        "    tweet = re.sub(r\"WMUR9\", \"WMUR-TV\", tweet)\n",
        "    tweet = re.sub(r\"RockBottomRadFM\", \"Rock Bottom Radio\", tweet)\n",
        "    tweet = re.sub(r\"ameenshaikh3\", \"Ameen Shaikh\", tweet)\n",
        "    tweet = re.sub(r\"ProSyn\", \"Project Syndicate\", tweet)\n",
        "    tweet = re.sub(r\"Daesh\", \"ISIS\", tweet)\n",
        "    tweet = re.sub(r\"s2g\", \"swear to god\", tweet)\n",
        "    tweet = re.sub(r\"listenlive\", \"listen live\", tweet)\n",
        "    tweet = re.sub(r\"CDCgov\", \"Centers for Disease Control and Prevention\", tweet)\n",
        "    tweet = re.sub(r\"FoxNew\", \"Fox News\", tweet)\n",
        "    tweet = re.sub(r\"CBSBigBrother\", \"Big Brother\", tweet)\n",
        "    tweet = re.sub(r\"JulieDiCaro\", \"Julie DiCaro\", tweet)\n",
        "    tweet = re.sub(r\"theadvocatemag\", \"The Advocate Magazine\", tweet)\n",
        "    tweet = re.sub(r\"RohnertParkDPS\", \"Rohnert Park Police Department\", tweet)\n",
        "    tweet = re.sub(r\"THISIZBWRIGHT\", \"Bonnie Wright\", tweet)\n",
        "    tweet = re.sub(r\"Popularmmos\", \"Popular MMOs\", tweet)\n",
        "    tweet = re.sub(r\"WildHorses\", \"Wild Horses\", tweet)\n",
        "    tweet = re.sub(r\"FantasticFour\", \"Fantastic Four\", tweet)\n",
        "    tweet = re.sub(r\"HORNDALE\", \"Horndale\", tweet)\n",
        "    tweet = re.sub(r\"PINER\", \"Piner\", tweet)\n",
        "    tweet = re.sub(r\"BathAndNorthEastSomerset\", \"Bath and North East Somerset\", tweet)\n",
        "    tweet = re.sub(r\"thatswhatfriendsarefor\", \"that is what friends are for\", tweet)\n",
        "    tweet = re.sub(r\"residualincome\", \"residual income\", tweet)\n",
        "    tweet = re.sub(r\"YahooNewsDigest\", \"Yahoo News Digest\", tweet)\n",
        "    tweet = re.sub(r\"MalaysiaAirlines\", \"Malaysia Airlines\", tweet)\n",
        "    tweet = re.sub(r\"AmazonDeals\", \"Amazon Deals\", tweet)\n",
        "    tweet = re.sub(r\"MissCharleyWebb\", \"Charley Webb\", tweet)\n",
        "    tweet = re.sub(r\"shoalstraffic\", \"shoals traffic\", tweet)\n",
        "    tweet = re.sub(r\"GeorgeFoster72\", \"George Foster\", tweet)\n",
        "    tweet = re.sub(r\"pop2015\", \"pop 2015\", tweet)\n",
        "    tweet = re.sub(r\"_PokemonCards_\", \"Pokemon Cards\", tweet)\n",
        "    tweet = re.sub(r\"DianneG\", \"Dianne Gallagher\", tweet)\n",
        "    tweet = re.sub(r\"KashmirConflict\", \"Kashmir Conflict\", tweet)\n",
        "    tweet = re.sub(r\"BritishBakeOff\", \"British Bake Off\", tweet)\n",
        "    tweet = re.sub(r\"FreeKashmir\", \"Free Kashmir\", tweet)\n",
        "    tweet = re.sub(r\"mattmosley\", \"Matt Mosley\", tweet)\n",
        "    tweet = re.sub(r\"BishopFred\", \"Bishop Fred\", tweet)\n",
        "    tweet = re.sub(r\"EndConflict\", \"End Conflict\", tweet)\n",
        "    tweet = re.sub(r\"EndOccupation\", \"End Occupation\", tweet)\n",
        "    tweet = re.sub(r\"UNHEALED\", \"unhealed\", tweet)\n",
        "    tweet = re.sub(r\"CharlesDagnall\", \"Charles Dagnall\", tweet)\n",
        "    tweet = re.sub(r\"Latestnews\", \"Latest news\", tweet)\n",
        "    tweet = re.sub(r\"KindleCountdown\", \"Kindle Countdown\", tweet)\n",
        "    tweet = re.sub(r\"NoMoreHandouts\", \"No More Handouts\", tweet)\n",
        "    tweet = re.sub(r\"datingtips\", \"dating tips\", tweet)\n",
        "    tweet = re.sub(r\"charlesadler\", \"Charles Adler\", tweet)\n",
        "    tweet = re.sub(r\"twia\", \"Texas Windstorm Insurance Association\", tweet)\n",
        "    tweet = re.sub(r\"txlege\", \"Texas Legislature\", tweet)\n",
        "    tweet = re.sub(r\"WindstormInsurer\", \"Windstorm Insurer\", tweet)\n",
        "    tweet = re.sub(r\"Newss\", \"News\", tweet)\n",
        "    tweet = re.sub(r\"hempoil\", \"hemp oil\", tweet)\n",
        "    tweet = re.sub(r\"CommoditiesAre\", \"Commodities are\", tweet)\n",
        "    tweet = re.sub(r\"tubestrike\", \"tube strike\", tweet)\n",
        "    tweet = re.sub(r\"JoeNBC\", \"Joe Scarborough\", tweet)\n",
        "    tweet = re.sub(r\"LiteraryCakes\", \"Literary Cakes\", tweet)\n",
        "    tweet = re.sub(r\"TI5\", \"The International 5\", tweet)\n",
        "    tweet = re.sub(r\"thehill\", \"the hill\", tweet)\n",
        "    tweet = re.sub(r\"3others\", \"3 others\", tweet)\n",
        "    tweet = re.sub(r\"stighefootball\", \"Sam Tighe\", tweet)\n",
        "    tweet = re.sub(r\"whatstheimportantvideo\", \"what is the important video\", tweet)\n",
        "    tweet = re.sub(r\"ClaudioMeloni\", \"Claudio Meloni\", tweet)\n",
        "    tweet = re.sub(r\"DukeSkywalker\", \"Duke Skywalker\", tweet)\n",
        "    tweet = re.sub(r\"carsonmwr\", \"Fort Carson\", tweet)\n",
        "    tweet = re.sub(r\"offdishduty\", \"off dish duty\", tweet)\n",
        "    tweet = re.sub(r\"andword\", \"and word\", tweet)\n",
        "    tweet = re.sub(r\"rhodeisland\", \"Rhode Island\", tweet)\n",
        "    tweet = re.sub(r\"easternoregon\", \"Eastern Oregon\", tweet)\n",
        "    tweet = re.sub(r\"WAwildfire\", \"Washington Wildfire\", tweet)\n",
        "    tweet = re.sub(r\"fingerrockfire\", \"Finger Rock Fire\", tweet)\n",
        "    tweet = re.sub(r\"57am\", \"57 am\", tweet)\n",
        "    tweet = re.sub(r\"fingerrockfire\", \"Finger Rock Fire\", tweet)\n",
        "    tweet = re.sub(r\"JacobHoggard\", \"Jacob Hoggard\", tweet)\n",
        "    tweet = re.sub(r\"newnewnew\", \"new new new\", tweet)\n",
        "    tweet = re.sub(r\"under50\", \"under 50\", tweet)\n",
        "    tweet = re.sub(r\"getitbeforeitsgone\", \"get it before it is gone\", tweet)\n",
        "    tweet = re.sub(r\"freshoutofthebox\", \"fresh out of the box\", tweet)\n",
        "    tweet = re.sub(r\"amwriting\", \"am writing\", tweet)\n",
        "    tweet = re.sub(r\"Bokoharm\", \"Boko Haram\", tweet)\n",
        "    tweet = re.sub(r\"Nowlike\", \"Now like\", tweet)\n",
        "    tweet = re.sub(r\"seasonfrom\", \"season from\", tweet)\n",
        "    tweet = re.sub(r\"epicente\", \"epicenter\", tweet)\n",
        "    tweet = re.sub(r\"epicenterr\", \"epicenter\", tweet)\n",
        "    tweet = re.sub(r\"sicklife\", \"sick life\", tweet)\n",
        "    tweet = re.sub(r\"yycweather\", \"Calgary Weather\", tweet)\n",
        "    tweet = re.sub(r\"calgarysun\", \"Calgary Sun\", tweet)\n",
        "    tweet = re.sub(r\"approachng\", \"approaching\", tweet)\n",
        "    tweet = re.sub(r\"evng\", \"evening\", tweet)\n",
        "    tweet = re.sub(r\"Sumthng\", \"something\", tweet)\n",
        "    tweet = re.sub(r\"EllenPompeo\", \"Ellen Pompeo\", tweet)\n",
        "    tweet = re.sub(r\"shondarhimes\", \"Shonda Rhimes\", tweet)\n",
        "    tweet = re.sub(r\"ABCNetwork\", \"ABC Network\", tweet)\n",
        "    tweet = re.sub(r\"SushmaSwaraj\", \"Sushma Swaraj\", tweet)\n",
        "    tweet = re.sub(r\"pray4japan\", \"Pray for Japan\", tweet)\n",
        "    tweet = re.sub(r\"hope4japan\", \"Hope for Japan\", tweet)\n",
        "    tweet = re.sub(r\"Illusionimagess\", \"Illusion images\", tweet)\n",
        "    tweet = re.sub(r\"SummerUnderTheStars\", \"Summer Under The Stars\", tweet)\n",
        "    tweet = re.sub(r\"ShallWeDance\", \"Shall We Dance\", tweet)\n",
        "    tweet = re.sub(r\"TCMParty\", \"TCM Party\", tweet)\n",
        "    tweet = re.sub(r\"marijuananews\", \"marijuana news\", tweet)\n",
        "    tweet = re.sub(r\"onbeingwithKristaTippett\", \"on being with Krista Tippett\", tweet)\n",
        "    tweet = re.sub(r\"Beingtweets\", \"Being tweets\", tweet)\n",
        "    tweet = re.sub(r\"newauthors\", \"new authors\", tweet)\n",
        "    tweet = re.sub(r\"remedyyyy\", \"remedy\", tweet)\n",
        "    tweet = re.sub(r\"44PM\", \"44 PM\", tweet)\n",
        "    tweet = re.sub(r\"HeadlinesApp\", \"Headlines App\", tweet)\n",
        "    tweet = re.sub(r\"40PM\", \"40 PM\", tweet)\n",
        "    tweet = re.sub(r\"myswc\", \"Severe Weather Center\", tweet)\n",
        "    tweet = re.sub(r\"ithats\", \"that is\", tweet)\n",
        "    tweet = re.sub(r\"icouldsitinthismomentforever\", \"I could sit in this moment forever\", tweet)\n",
        "    tweet = re.sub(r\"FatLoss\", \"Fat Loss\", tweet)\n",
        "    tweet = re.sub(r\"02PM\", \"02 PM\", tweet)\n",
        "    tweet = re.sub(r\"MetroFmTalk\", \"Metro Fm Talk\", tweet)\n",
        "    tweet = re.sub(r\"Bstrd\", \"bastard\", tweet)\n",
        "    tweet = re.sub(r\"bldy\", \"bloody\", tweet)\n",
        "    tweet = re.sub(r\"MetrofmTalk\", \"Metro Fm Talk\", tweet)\n",
        "    tweet = re.sub(r\"terrorismturn\", \"terrorism turn\", tweet)\n",
        "    tweet = re.sub(r\"BBCNewsAsia\", \"BBC News Asia\", tweet)\n",
        "    tweet = re.sub(r\"BehindTheScenes\", \"Behind The Scenes\", tweet)\n",
        "    tweet = re.sub(r\"GeorgeTakei\", \"George Takei\", tweet)\n",
        "    tweet = re.sub(r\"WomensWeeklyMag\", \"Womens Weekly Magazine\", tweet)\n",
        "    tweet = re.sub(r\"SurvivorsGuidetoEarth\", \"Survivors Guide to Earth\", tweet)\n",
        "    tweet = re.sub(r\"incubusband\", \"incubus band\", tweet)\n",
        "    tweet = re.sub(r\"Babypicturethis\", \"Baby picture this\", tweet)\n",
        "    tweet = re.sub(r\"BombEffects\", \"Bomb Effects\", tweet)\n",
        "    tweet = re.sub(r\"win10\", \"Windows 10\", tweet)\n",
        "    tweet = re.sub(r\"idkidk\", \"I do not know I do not know\", tweet)\n",
        "    tweet = re.sub(r\"TheWalkingDead\", \"The Walking Dead\", tweet)\n",
        "    tweet = re.sub(r\"amyschumer\", \"Amy Schumer\", tweet)\n",
        "    tweet = re.sub(r\"crewlist\", \"crew list\", tweet)\n",
        "    tweet = re.sub(r\"Erdogans\", \"Erdogan\", tweet)\n",
        "    tweet = re.sub(r\"BBCLive\", \"BBC Live\", tweet)\n",
        "    tweet = re.sub(r\"TonyAbbottMHR\", \"Tony Abbott\", tweet)\n",
        "    tweet = re.sub(r\"paulmyerscough\", \"Paul Myerscough\", tweet)\n",
        "    tweet = re.sub(r\"georgegallagher\", \"George Gallagher\", tweet)\n",
        "    tweet = re.sub(r\"JimmieJohnson\", \"Jimmie Johnson\", tweet)\n",
        "    tweet = re.sub(r\"pctool\", \"pc tool\", tweet)\n",
        "    tweet = re.sub(r\"DoingHashtagsRight\", \"Doing Hashtags Right\", tweet)\n",
        "    tweet = re.sub(r\"ThrowbackThursday\", \"Throwback Thursday\", tweet)\n",
        "    tweet = re.sub(r\"SnowBackSunday\", \"Snowback Sunday\", tweet)\n",
        "    tweet = re.sub(r\"LakeEffect\", \"Lake Effect\", tweet)\n",
        "    tweet = re.sub(r\"RTphotographyUK\", \"Richard Thomas Photography UK\", tweet)\n",
        "    tweet = re.sub(r\"BigBang_CBS\", \"Big Bang CBS\", tweet)\n",
        "    tweet = re.sub(r\"writerslife\", \"writers life\", tweet)\n",
        "    tweet = re.sub(r\"NaturalBirth\", \"Natural Birth\", tweet)\n",
        "    tweet = re.sub(r\"UnusualWords\", \"Unusual Words\", tweet)\n",
        "    tweet = re.sub(r\"wizkhalifa\", \"Wiz Khalifa\", tweet)\n",
        "    tweet = re.sub(r\"acreativedc\", \"a creative DC\", tweet)\n",
        "    tweet = re.sub(r\"vscodc\", \"vsco DC\", tweet)\n",
        "    tweet = re.sub(r\"VSCOcam\", \"vsco camera\", tweet)\n",
        "    tweet = re.sub(r\"TheBEACHDC\", \"The beach DC\", tweet)\n",
        "    tweet = re.sub(r\"buildingmuseum\", \"building museum\", tweet)\n",
        "    tweet = re.sub(r\"WorldOil\", \"World Oil\", tweet)\n",
        "    tweet = re.sub(r\"redwedding\", \"red wedding\", tweet)\n",
        "    tweet = re.sub(r\"AmazingRaceCanada\", \"Amazing Race Canada\", tweet)\n",
        "    tweet = re.sub(r\"WakeUpAmerica\", \"Wake Up America\", tweet)\n",
        "    tweet = re.sub(r\"\\\\Allahuakbar\\\\\", \"Allahu Akbar\", tweet)\n",
        "    tweet = re.sub(r\"bleased\", \"blessed\", tweet)\n",
        "    tweet = re.sub(r\"nigeriantribune\", \"Nigerian Tribune\", tweet)\n",
        "    tweet = re.sub(r\"HIDEO_KOJIMA_EN\", \"Hideo Kojima\", tweet)\n",
        "    tweet = re.sub(r\"FusionFestival\", \"Fusion Festival\", tweet)\n",
        "    tweet = re.sub(r\"50Mixed\", \"50 Mixed\", tweet)\n",
        "    tweet = re.sub(r\"NoAgenda\", \"No Agenda\", tweet)\n",
        "    tweet = re.sub(r\"WhiteGenocide\", \"White Genocide\", tweet)\n",
        "    tweet = re.sub(r\"dirtylying\", \"dirty lying\", tweet)\n",
        "    tweet = re.sub(r\"SyrianRefugees\", \"Syrian Refugees\", tweet)\n",
        "    tweet = re.sub(r\"changetheworld\", \"change the world\", tweet)\n",
        "    tweet = re.sub(r\"Ebolacase\", \"Ebola case\", tweet)\n",
        "    tweet = re.sub(r\"mcgtech\", \"mcg technologies\", tweet)\n",
        "    tweet = re.sub(r\"withweapons\", \"with weapons\", tweet)\n",
        "    tweet = re.sub(r\"advancedwarfare\", \"advanced warfare\", tweet)\n",
        "    tweet = re.sub(r\"letsFootball\", \"let us Football\", tweet)\n",
        "    tweet = re.sub(r\"LateNiteMix\", \"late night mix\", tweet)\n",
        "    tweet = re.sub(r\"PhilCollinsFeed\", \"Phil Collins\", tweet)\n",
        "    tweet = re.sub(r\"RudyHavenstein\", \"Rudy Havenstein\", tweet)\n",
        "    tweet = re.sub(r\"22PM\", \"22 PM\", tweet)\n",
        "    tweet = re.sub(r\"54am\", \"54 AM\", tweet)\n",
        "    tweet = re.sub(r\"38am\", \"38 AM\", tweet)\n",
        "    tweet = re.sub(r\"OldFolkExplainStuff\", \"Old Folk Explain Stuff\", tweet)\n",
        "    tweet = re.sub(r\"BlacklivesMatter\", \"Black Lives Matter\", tweet)\n",
        "    tweet = re.sub(r\"InsaneLimits\", \"Insane Limits\", tweet)\n",
        "    tweet = re.sub(r\"youcantsitwithus\", \"you cannot sit with us\", tweet)\n",
        "    tweet = re.sub(r\"2k15\", \"2015\", tweet)\n",
        "    tweet = re.sub(r\"TheIran\", \"Iran\", tweet)\n",
        "    tweet = re.sub(r\"JimmyFallon\", \"Jimmy Fallon\", tweet)\n",
        "    tweet = re.sub(r\"AlbertBrooks\", \"Albert Brooks\", tweet)\n",
        "    tweet = re.sub(r\"defense_news\", \"defense news\", tweet)\n",
        "    tweet = re.sub(r\"nuclearrcSA\", \"Nuclear Risk Control Self Assessment\", tweet)\n",
        "    tweet = re.sub(r\"Auspol\", \"Australia Politics\", tweet)\n",
        "    tweet = re.sub(r\"NuclearPower\", \"Nuclear Power\", tweet)\n",
        "    tweet = re.sub(r\"WhiteTerrorism\", \"White Terrorism\", tweet)\n",
        "    tweet = re.sub(r\"truthfrequencyradio\", \"Truth Frequency Radio\", tweet)\n",
        "    tweet = re.sub(r\"ErasureIsNotEquality\", \"Erasure is not equality\", tweet)\n",
        "    tweet = re.sub(r\"ProBonoNews\", \"Pro Bono News\", tweet)\n",
        "    tweet = re.sub(r\"JakartaPost\", \"Jakarta Post\", tweet)\n",
        "    tweet = re.sub(r\"toopainful\", \"too painful\", tweet)\n",
        "    tweet = re.sub(r\"melindahaunton\", \"Melinda Haunton\", tweet)\n",
        "    tweet = re.sub(r\"NoNukes\", \"No Nukes\", tweet)\n",
        "    tweet = re.sub(r\"curryspcworld\", \"Currys PC World\", tweet)\n",
        "    tweet = re.sub(r\"ineedcake\", \"I need cake\", tweet)\n",
        "    tweet = re.sub(r\"blackforestgateau\", \"black forest gateau\", tweet)\n",
        "    tweet = re.sub(r\"BBCOne\", \"BBC One\", tweet)\n",
        "    tweet = re.sub(r\"AlexxPage\", \"Alex Page\", tweet)\n",
        "    tweet = re.sub(r\"jonathanserrie\", \"Jonathan Serrie\", tweet)\n",
        "    tweet = re.sub(r\"SocialJerkBlog\", \"Social Jerk Blog\", tweet)\n",
        "    tweet = re.sub(r\"ChelseaVPeretti\", \"Chelsea Peretti\", tweet)\n",
        "    tweet = re.sub(r\"irongiant\", \"iron giant\", tweet)\n",
        "    tweet = re.sub(r\"RonFunches\", \"Ron Funches\", tweet)\n",
        "    tweet = re.sub(r\"TimCook\", \"Tim Cook\", tweet)\n",
        "    tweet = re.sub(r\"sebastianstanisaliveandwell\", \"Sebastian Stan is alive and well\", tweet)\n",
        "    tweet = re.sub(r\"Madsummer\", \"Mad summer\", tweet)\n",
        "    tweet = re.sub(r\"NowYouKnow\", \"Now you know\", tweet)\n",
        "    tweet = re.sub(r\"concertphotography\", \"concert photography\", tweet)\n",
        "    tweet = re.sub(r\"TomLandry\", \"Tom Landry\", tweet)\n",
        "    tweet = re.sub(r\"showgirldayoff\", \"show girl day off\", tweet)\n",
        "    tweet = re.sub(r\"Yougslavia\", \"Yugoslavia\", tweet)\n",
        "    tweet = re.sub(r\"QuantumDataInformatics\", \"Quantum Data Informatics\", tweet)\n",
        "    tweet = re.sub(r\"FromTheDesk\", \"From The Desk\", tweet)\n",
        "    tweet = re.sub(r\"TheaterTrial\", \"Theater Trial\", tweet)\n",
        "    tweet = re.sub(r\"CatoInstitute\", \"Cato Institute\", tweet)\n",
        "    tweet = re.sub(r\"EmekaGift\", \"Emeka Gift\", tweet)\n",
        "    tweet = re.sub(r\"LetsBe_Rational\", \"Let us be rational\", tweet)\n",
        "    tweet = re.sub(r\"Cynicalreality\", \"Cynical reality\", tweet)\n",
        "    tweet = re.sub(r\"FredOlsenCruise\", \"Fred Olsen Cruise\", tweet)\n",
        "    tweet = re.sub(r\"NotSorry\", \"not sorry\", tweet)\n",
        "    tweet = re.sub(r\"UseYourWords\", \"use your words\", tweet)\n",
        "    tweet = re.sub(r\"WordoftheDay\", \"word of the day\", tweet)\n",
        "    tweet = re.sub(r\"Dictionarycom\", \"Dictionary.com\", tweet)\n",
        "    tweet = re.sub(r\"TheBrooklynLife\", \"The Brooklyn Life\", tweet)\n",
        "    tweet = re.sub(r\"jokethey\", \"joke they\", tweet)\n",
        "    tweet = re.sub(r\"nflweek1picks\", \"NFL week 1 picks\", tweet)\n",
        "    tweet = re.sub(r\"uiseful\", \"useful\", tweet)\n",
        "    tweet = re.sub(r\"JusticeDotOrg\", \"The American Association for Justice\", tweet)\n",
        "    tweet = re.sub(r\"autoaccidents\", \"auto accidents\", tweet)\n",
        "    tweet = re.sub(r\"SteveGursten\", \"Steve Gursten\", tweet)\n",
        "    tweet = re.sub(r\"MichiganAutoLaw\", \"Michigan Auto Law\", tweet)\n",
        "    tweet = re.sub(r\"birdgang\", \"bird gang\", tweet)\n",
        "    tweet = re.sub(r\"nflnetwork\", \"NFL Network\", tweet)\n",
        "    tweet = re.sub(r\"NYDNSports\", \"NY Daily News Sports\", tweet)\n",
        "    tweet = re.sub(r\"RVacchianoNYDN\", \"Ralph Vacchiano NY Daily News\", tweet)\n",
        "    tweet = re.sub(r\"EdmontonEsks\", \"Edmonton Eskimos\", tweet)\n",
        "    tweet = re.sub(r\"david_brelsford\", \"David Brelsford\", tweet)\n",
        "    tweet = re.sub(r\"TOI_India\", \"The Times of India\", tweet)\n",
        "    tweet = re.sub(r\"hegot\", \"he got\", tweet)\n",
        "    tweet = re.sub(r\"SkinsOn9\", \"Skins on 9\", tweet)\n",
        "    tweet = re.sub(r\"sothathappened\", \"so that happened\", tweet)\n",
        "    tweet = re.sub(r\"LCOutOfDoors\", \"LC Out Of Doors\", tweet)\n",
        "    tweet = re.sub(r\"NationFirst\", \"Nation First\", tweet)\n",
        "    tweet = re.sub(r\"IndiaToday\", \"India Today\", tweet)\n",
        "    tweet = re.sub(r\"HLPS\", \"helps\", tweet)\n",
        "    tweet = re.sub(r\"HOSTAGESTHROSW\", \"hostages throw\", tweet)\n",
        "    tweet = re.sub(r\"SNCTIONS\", \"sanctions\", tweet)\n",
        "    tweet = re.sub(r\"BidTime\", \"Bid Time\", tweet)\n",
        "    tweet = re.sub(r\"crunchysensible\", \"crunchy sensible\", tweet)\n",
        "    tweet = re.sub(r\"RandomActsOfRomance\", \"Random acts of romance\", tweet)\n",
        "    tweet = re.sub(r\"MomentsAtHill\", \"Moments at hill\", tweet)\n",
        "    tweet = re.sub(r\"eatshit\", \"eat shit\", tweet)\n",
        "    tweet = re.sub(r\"liveleakfun\", \"live leak fun\", tweet)\n",
        "    tweet = re.sub(r\"SahelNews\", \"Sahel News\", tweet)\n",
        "    tweet = re.sub(r\"abc7newsbayarea\", \"ABC 7 News Bay Area\", tweet)\n",
        "    tweet = re.sub(r\"facilitiesmanagement\", \"facilities management\", tweet)\n",
        "    tweet = re.sub(r\"facilitydude\", \"facility dude\", tweet)\n",
        "    tweet = re.sub(r\"CampLogistics\", \"Camp logistics\", tweet)\n",
        "    tweet = re.sub(r\"alaskapublic\", \"Alaska public\", tweet)\n",
        "    tweet = re.sub(r\"MarketResearch\", \"Market Research\", tweet)\n",
        "    tweet = re.sub(r\"AccuracyEsports\", \"Accuracy Esports\", tweet)\n",
        "    tweet = re.sub(r\"TheBodyShopAust\", \"The Body Shop Australia\", tweet)\n",
        "    tweet = re.sub(r\"yychail\", \"Calgary hail\", tweet)\n",
        "    tweet = re.sub(r\"yyctraffic\", \"Calgary traffic\", tweet)\n",
        "    tweet = re.sub(r\"eliotschool\", \"eliot school\", tweet)\n",
        "    tweet = re.sub(r\"TheBrokenCity\", \"The Broken City\", tweet)\n",
        "    tweet = re.sub(r\"OldsFireDept\", \"Olds Fire Department\", tweet)\n",
        "    tweet = re.sub(r\"RiverComplex\", \"River Complex\", tweet)\n",
        "    tweet = re.sub(r\"fieldworksmells\", \"field work smells\", tweet)\n",
        "    tweet = re.sub(r\"IranElection\", \"Iran Election\", tweet)\n",
        "    tweet = re.sub(r\"glowng\", \"glowing\", tweet)\n",
        "    tweet = re.sub(r\"kindlng\", \"kindling\", tweet)\n",
        "    tweet = re.sub(r\"riggd\", \"rigged\", tweet)\n",
        "    tweet = re.sub(r\"slownewsday\", \"slow news day\", tweet)\n",
        "    tweet = re.sub(r\"MyanmarFlood\", \"Myanmar Flood\", tweet)\n",
        "    tweet = re.sub(r\"abc7chicago\", \"ABC 7 Chicago\", tweet)\n",
        "    tweet = re.sub(r\"copolitics\", \"Colorado Politics\", tweet)\n",
        "    tweet = re.sub(r\"AdilGhumro\", \"Adil Ghumro\", tweet)\n",
        "    tweet = re.sub(r\"netbots\", \"net bots\", tweet)\n",
        "    tweet = re.sub(r\"byebyeroad\", \"bye bye road\", tweet)\n",
        "    tweet = re.sub(r\"massiveflooding\", \"massive flooding\", tweet)\n",
        "    tweet = re.sub(r\"EndofUS\", \"End of United States\", tweet)\n",
        "    tweet = re.sub(r\"35PM\", \"35 PM\", tweet)\n",
        "    tweet = re.sub(r\"greektheatrela\", \"Greek Theatre Los Angeles\", tweet)\n",
        "    tweet = re.sub(r\"76mins\", \"76 minutes\", tweet)\n",
        "    tweet = re.sub(r\"publicsafetyfirst\", \"public safety first\", tweet)\n",
        "    tweet = re.sub(r\"livesmatter\", \"lives matter\", tweet)\n",
        "    tweet = re.sub(r\"myhometown\", \"my hometown\", tweet)\n",
        "    tweet = re.sub(r\"tankerfire\", \"tanker fire\", tweet)\n",
        "    tweet = re.sub(r\"MEMORIALDAY\", \"memorial day\", tweet)\n",
        "    tweet = re.sub(r\"MEMORIAL_DAY\", \"memorial day\", tweet)\n",
        "    tweet = re.sub(r\"instaxbooty\", \"instagram booty\", tweet)\n",
        "    tweet = re.sub(r\"Jerusalem_Post\", \"Jerusalem Post\", tweet)\n",
        "    tweet = re.sub(r\"WayneRooney_INA\", \"Wayne Rooney\", tweet)\n",
        "    tweet = re.sub(r\"VirtualReality\", \"Virtual Reality\", tweet)\n",
        "    tweet = re.sub(r\"OculusRift\", \"Oculus Rift\", tweet)\n",
        "    tweet = re.sub(r\"OwenJones84\", \"Owen Jones\", tweet)\n",
        "    tweet = re.sub(r\"jeremycorbyn\", \"Jeremy Corbyn\", tweet)\n",
        "    tweet = re.sub(r\"paulrogers002\", \"Paul Rogers\", tweet)\n",
        "    tweet = re.sub(r\"mortalkombatx\", \"Mortal Kombat X\", tweet)\n",
        "    tweet = re.sub(r\"mortalkombat\", \"Mortal Kombat\", tweet)\n",
        "    tweet = re.sub(r\"FilipeCoelho92\", \"Filipe Coelho\", tweet)\n",
        "    tweet = re.sub(r\"OnlyQuakeNews\", \"Only Quake News\", tweet)\n",
        "    tweet = re.sub(r\"kostumes\", \"costumes\", tweet)\n",
        "    tweet = re.sub(r\"YEEESSSS\", \"yes\", tweet)\n",
        "    tweet = re.sub(r\"ToshikazuKatayama\", \"Toshikazu Katayama\", tweet)\n",
        "    tweet = re.sub(r\"IntlDevelopment\", \"Intl Development\", tweet)\n",
        "    tweet = re.sub(r\"ExtremeWeather\", \"Extreme Weather\", tweet)\n",
        "    tweet = re.sub(r\"WereNotGruberVoters\", \"We are not gruber voters\", tweet)\n",
        "    tweet = re.sub(r\"NewsThousands\", \"News Thousands\", tweet)\n",
        "    tweet = re.sub(r\"EdmundAdamus\", \"Edmund Adamus\", tweet)\n",
        "    tweet = re.sub(r\"EyewitnessWV\", \"Eye witness WV\", tweet)\n",
        "    tweet = re.sub(r\"PhiladelphiaMuseu\", \"Philadelphia Museum\", tweet)\n",
        "    tweet = re.sub(r\"DublinComicCon\", \"Dublin Comic Con\", tweet)\n",
        "    tweet = re.sub(r\"NicholasBrendon\", \"Nicholas Brendon\", tweet)\n",
        "    tweet = re.sub(r\"Alltheway80s\", \"All the way 80s\", tweet)\n",
        "    tweet = re.sub(r\"FromTheField\", \"From the field\", tweet)\n",
        "    tweet = re.sub(r\"NorthIowa\", \"North Iowa\", tweet)\n",
        "    tweet = re.sub(r\"WillowFire\", \"Willow Fire\", tweet)\n",
        "    tweet = re.sub(r\"MadRiverComplex\", \"Mad River Complex\", tweet)\n",
        "    tweet = re.sub(r\"feelingmanly\", \"feeling manly\", tweet)\n",
        "    tweet = re.sub(r\"stillnotoverit\", \"still not over it\", tweet)\n",
        "    tweet = re.sub(r\"FortitudeValley\", \"Fortitude Valley\", tweet)\n",
        "    tweet = re.sub(r\"CoastpowerlineTramTr\", \"Coast powerline\", tweet)\n",
        "    tweet = re.sub(r\"ServicesGold\", \"Services Gold\", tweet)\n",
        "    tweet = re.sub(r\"NewsbrokenEmergency\", \"News broken emergency\", tweet)\n",
        "    tweet = re.sub(r\"Evaucation\", \"evacuation\", tweet)\n",
        "    tweet = re.sub(r\"leaveevacuateexitbe\", \"leave evacuate exit be\", tweet)\n",
        "    tweet = re.sub(r\"P_EOPLE\", \"PEOPLE\", tweet)\n",
        "    tweet = re.sub(r\"Tubestrike\", \"tube strike\", tweet)\n",
        "    tweet = re.sub(r\"CLASS_SICK\", \"CLASS SICK\", tweet)\n",
        "    tweet = re.sub(r\"localplumber\", \"local plumber\", tweet)\n",
        "    tweet = re.sub(r\"awesomejobsiri\", \"awesome job siri\", tweet)\n",
        "    tweet = re.sub(r\"PayForItHow\", \"Pay for it how\", tweet)\n",
        "    tweet = re.sub(r\"ThisIsAfrica\", \"This is Africa\", tweet)\n",
        "    tweet = re.sub(r\"crimeairnetwork\", \"crime air network\", tweet)\n",
        "    tweet = re.sub(r\"KimAcheson\", \"Kim Acheson\", tweet)\n",
        "    tweet = re.sub(r\"cityofcalgary\", \"City of Calgary\", tweet)\n",
        "    tweet = re.sub(r\"prosyndicate\", \"pro syndicate\", tweet)\n",
        "    tweet = re.sub(r\"660NEWS\", \"660 NEWS\", tweet)\n",
        "    tweet = re.sub(r\"BusInsMagazine\", \"Business Insurance Magazine\", tweet)\n",
        "    tweet = re.sub(r\"wfocus\", \"focus\", tweet)\n",
        "    tweet = re.sub(r\"ShastaDam\", \"Shasta Dam\", tweet)\n",
        "    tweet = re.sub(r\"go2MarkFranco\", \"Mark Franco\", tweet)\n",
        "    tweet = re.sub(r\"StephGHinojosa\", \"Steph Hinojosa\", tweet)\n",
        "    tweet = re.sub(r\"Nashgrier\", \"Nash Grier\", tweet)\n",
        "    tweet = re.sub(r\"NashNewVideo\", \"Nash new video\", tweet)\n",
        "    tweet = re.sub(r\"IWouldntGetElectedBecause\", \"I would not get elected because\", tweet)\n",
        "    tweet = re.sub(r\"SHGames\", \"Sledgehammer Games\", tweet)\n",
        "    tweet = re.sub(r\"bedhair\", \"bed hair\", tweet)\n",
        "    tweet = re.sub(r\"JoelHeyman\", \"Joel Heyman\", tweet)\n",
        "    tweet = re.sub(r\"viaYouTube\", \"via YouTube\", tweet)\n",
        "           \n",
        "    # Urls\n",
        "    tweet = re.sub(r\"https?:\\/\\/t.co\\/[A-Za-z0-9]+\", \"\", tweet)\n",
        "        \n",
        "    # Words with punctuations and special characters\n",
        "    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\"\n",
        "    for p in punctuations:\n",
        "        tweet = tweet.replace(p, f' {p} ')\n",
        "        \n",
        "    # ... and ..\n",
        "    tweet = tweet.replace('...', ' ... ')\n",
        "    if '...' not in tweet:\n",
        "        tweet = tweet.replace('..', ' ... ')      \n",
        "        \n",
        "    # Acronyms\n",
        "    tweet = re.sub(r\"MH370\", \"Malaysia Airlines Flight 370\", tweet)\n",
        "    tweet = re.sub(r\"mÌ¼sica\", \"music\", tweet)\n",
        "    tweet = re.sub(r\"okwx\", \"Oklahoma City Weather\", tweet)\n",
        "    tweet = re.sub(r\"arwx\", \"Arkansas Weather\", tweet)    \n",
        "    tweet = re.sub(r\"gawx\", \"Georgia Weather\", tweet)  \n",
        "    tweet = re.sub(r\"scwx\", \"South Carolina Weather\", tweet)  \n",
        "    tweet = re.sub(r\"cawx\", \"California Weather\", tweet)\n",
        "    tweet = re.sub(r\"tnwx\", \"Tennessee Weather\", tweet)\n",
        "    tweet = re.sub(r\"azwx\", \"Arizona Weather\", tweet)  \n",
        "    tweet = re.sub(r\"alwx\", \"Alabama Weather\", tweet)\n",
        "    tweet = re.sub(r\"wordpressdotcom\", \"wordpress\", tweet)    \n",
        "    tweet = re.sub(r\"usNWSgov\", \"United States National Weather Service\", tweet)\n",
        "    tweet = re.sub(r\"Suruc\", \"Sanliurfa\", tweet)   \n",
        "    \n",
        "    # Grouping same words without embeddings\n",
        "    tweet = re.sub(r\"Bestnaijamade\", \"bestnaijamade\", tweet)\n",
        "    tweet = re.sub(r\"SOUDELOR\", \"Soudelor\", tweet)\n",
        "    \n",
        "    return tweet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dhz--99fqSP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_Train['text'] = df_Train['text'].apply(lambda x : clean(x))\n",
        "df_Test['text'] = df_Test['text'].apply(lambda x : clean(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVYmNGaJRi3a",
        "colab_type": "text"
      },
      "source": [
        "### Remove HTML Links"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfesXqklTZJz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "def remove_HTML(text):\n",
        "  html = re.compile(r'<.*?>')\n",
        "  return html.sub(r'',text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPw8Xkq7Tw7N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_Train['text'] = df_Train['text'].apply(lambda x : remove_HTML(x))\n",
        "df_Test['text'] = df_Test['text'].apply(lambda x : remove_HTML(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vD4Xw1sUaAb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "77a20dc9-5813-487c-f7b7-1d5440212a7f"
      },
      "source": [
        "df_Train['text'].head(15)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     Our Deeds are the Reason of this #earthquake M...\n",
              "1                Forest fire near La Ronge Sask. Canada\n",
              "2     All residents asked to 'shelter in place' are ...\n",
              "3     13,000 people receive #wildfires evacuation or...\n",
              "4     Just got sent this photo from Ruby #Alaska as ...\n",
              "5     #RockyFire Update => California Hwy. 20 closed...\n",
              "6     #flood #disaster Heavy rain causes flash flood...\n",
              "7     I'm on top of the hill and I can see a fire in...\n",
              "8     There's an emergency evacuation happening now ...\n",
              "9     I'm afraid that the tornado is coming to our a...\n",
              "10          Three people died from the heat wave so far\n",
              "11    Haha South Tampa is getting flooded hah- WAIT ...\n",
              "12    #raining #flooding #Florida #TampaBay #Tampa 1...\n",
              "13              #Flood in Bago Myanmar #We arrived Bago\n",
              "14    Damage to school bus on 80 in multi car crash ...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6FehoSAUqwN",
        "colab_type": "text"
      },
      "source": [
        "### Remove Web URL's"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVkqrWSwUj3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "def remove_URL(text):\n",
        "  url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "  return url.sub(r'', text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwSgcbfiVJFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_Train['text'] = df_Train['text'].apply(lambda x : remove_URL(x))\n",
        "df_Test['text'] = df_Test['text'].apply(lambda x : remove_URL(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSUdaLGEXRsh",
        "colab_type": "text"
      },
      "source": [
        "### Remove Emojis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nqDz4NHXUu2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBW3-P_tXZCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_Train['text'] = df_Train['text'].apply(lambda x : remove_emoji(x))\n",
        "df_Test['text'] = df_Test['text'].apply(lambda x : remove_emoji(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGFz_BTnYQCE",
        "colab_type": "text"
      },
      "source": [
        "### Remove Punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6R4w7ZYYTLp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    no_punct = \"\".join([c for c in text if c not in string.punctuation])\n",
        "    return no_punct"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0tn97e9YUUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_Train['text'] = df_Train['text'].apply(lambda x : remove_punctuation(x))\n",
        "df_Test['text'] = df_Test['text'].apply(lambda x : remove_punctuation(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaJHeH1IYYj1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "6835c101-ea85-4afa-b9a1-8ea2020a8e3a"
      },
      "source": [
        "df_Train['text'].head(15)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     Our Deeds are the Reason of this earthquake Ma...\n",
              "1                 Forest fire near La Ronge Sask Canada\n",
              "2     All residents asked to shelter in place are be...\n",
              "3     13000 people receive wildfires evacuation orde...\n",
              "4     Just got sent this photo from Ruby Alaska as s...\n",
              "5     RockyFire Update  California Hwy 20 closed in ...\n",
              "6     flood disaster Heavy rain causes flash floodin...\n",
              "7     Im on top of the hill and I can see a fire in ...\n",
              "8     Theres an emergency evacuation happening now i...\n",
              "9      Im afraid that the tornado is coming to our area\n",
              "10          Three people died from the heat wave so far\n",
              "11    Haha South Tampa is getting flooded hah WAIT A...\n",
              "12    raining flooding Florida TampaBay Tampa 18 or ...\n",
              "13                Flood in Bago Myanmar We arrived Bago\n",
              "14    Damage to school bus on 80 in multi car crash ...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0GECNKjY8mh",
        "colab_type": "text"
      },
      "source": [
        "### Remove STOPWORDS and lower case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy0Dlp4IY_HJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "22df030c-d133-4a1e-e8fe-7a29ecfb48d2"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kZKxHqMn5Bh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stopwords = set(nltk.corpus.stopwords.words())\n",
        "def clean_stopwords(text):\n",
        "    res = []\n",
        "    for word in text:\n",
        "        if word not in stopwords:\n",
        "            res.append(word)\n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Myqx88LnZElU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_Train['text'] = df_Train['text'].apply(lambda x: \" \".join(lemmatizer.lemmatize(x.lower(),pos='v') for x in x.split() if x not in stop_words))\n",
        "df_Test['text'] = df_Test['text'].apply(lambda x: \" \".join(lemmatizer.lemmatize(x.lower(),pos='v') for x in x.split() if x not in stop_words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxo2cm43a9LG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "f75a6bfb-5f12-4981-f3e6-a29b1af837fd"
      },
      "source": [
        "df_Train['text'].head(15)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      our deeds reason earthquake may allah forgive us\n",
              "1                 forest fire near la ronge sask canada\n",
              "2     all residents ask shelter place notify officer...\n",
              "3     13000 people receive wildfires evacuation orde...\n",
              "4     just get send photo ruby alaska smoke wildfire...\n",
              "5     rockyfire update california hwy 20 close direc...\n",
              "6     flood disaster heavy rain cause flash flood st...\n",
              "7                          im top hill i see fire woods\n",
              "8     theres emergency evacuation happen build acros...\n",
              "9                           im afraid tornado come area\n",
              "10                       three people die heat wave far\n",
              "11    haha south tampa get flood hah wait a second i...\n",
              "12    rain flood florida tampabay tampa 18 19 days i...\n",
              "13                    flood bago myanmar we arrive bago\n",
              "14           damage school bus 80 multi car crash break\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch3ZNEiFbokz",
        "colab_type": "text"
      },
      "source": [
        "### Remove Additional Spaces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNtMBShjbr4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_Train['text'] = df_Train['text'].apply(lambda x: \" \".join(x for x in x.split() if len(x)> 1))\n",
        "df_Test['text'] = df_Test['text'].apply(lambda x: \" \".join(x for x in x.split() if len(x)> 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Rj6WrIyb_gi",
        "colab_type": "text"
      },
      "source": [
        "### Spell Checker"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xs7ozoC4cHTZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "77949b3c-1cd5-4c5a-ac3a-3d7fb8b26a13"
      },
      "source": [
        "pip install pyspellchecker"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspellchecker\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/d1/ec4e830e9f9c1fd788e1459dd09279fdf807bc7a475579fd7192450b879c/pyspellchecker-0.5.4-py2.py3-none-any.whl (1.9MB)\n",
            "\r\u001b[K     |▏                               | 10kB 18.9MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 6.8MB/s eta 0:00:01\r\u001b[K     |▌                               | 30kB 9.4MB/s eta 0:00:01\r\u001b[K     |▊                               | 40kB 11.7MB/s eta 0:00:01\r\u001b[K     |▉                               | 51kB 7.7MB/s eta 0:00:01\r\u001b[K     |█                               | 61kB 8.6MB/s eta 0:00:01\r\u001b[K     |█▏                              | 71kB 9.6MB/s eta 0:00:01\r\u001b[K     |█▍                              | 81kB 10.7MB/s eta 0:00:01\r\u001b[K     |█▌                              | 92kB 9.0MB/s eta 0:00:01\r\u001b[K     |█▊                              | 102kB 9.7MB/s eta 0:00:01\r\u001b[K     |█▉                              | 112kB 9.7MB/s eta 0:00:01\r\u001b[K     |██                              | 122kB 9.7MB/s eta 0:00:01\r\u001b[K     |██▎                             | 133kB 9.7MB/s eta 0:00:01\r\u001b[K     |██▍                             | 143kB 9.7MB/s eta 0:00:01\r\u001b[K     |██▋                             | 153kB 9.7MB/s eta 0:00:01\r\u001b[K     |██▊                             | 163kB 9.7MB/s eta 0:00:01\r\u001b[K     |███                             | 174kB 9.7MB/s eta 0:00:01\r\u001b[K     |███                             | 184kB 9.7MB/s eta 0:00:01\r\u001b[K     |███▎                            | 194kB 9.7MB/s eta 0:00:01\r\u001b[K     |███▍                            | 204kB 9.7MB/s eta 0:00:01\r\u001b[K     |███▋                            | 215kB 9.7MB/s eta 0:00:01\r\u001b[K     |███▊                            | 225kB 9.7MB/s eta 0:00:01\r\u001b[K     |████                            | 235kB 9.7MB/s eta 0:00:01\r\u001b[K     |████▏                           | 245kB 9.7MB/s eta 0:00:01\r\u001b[K     |████▎                           | 256kB 9.7MB/s eta 0:00:01\r\u001b[K     |████▌                           | 266kB 9.7MB/s eta 0:00:01\r\u001b[K     |████▋                           | 276kB 9.7MB/s eta 0:00:01\r\u001b[K     |████▉                           | 286kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 296kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 307kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 317kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 327kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 337kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 348kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 358kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 368kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 378kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 389kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 399kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 409kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 419kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 430kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 440kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 450kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 460kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 471kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 481kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 491kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 501kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 512kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 522kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 532kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 542kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 552kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 563kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 573kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 583kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 593kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 604kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 614kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 624kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 634kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 645kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 655kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 665kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 675kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 686kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 696kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 706kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 716kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 727kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 737kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 747kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 757kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 768kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 778kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 788kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 798kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 808kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 819kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 829kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 839kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 849kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 860kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 870kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 880kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 890kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 901kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 911kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 921kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 931kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 942kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 952kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 962kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 972kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 983kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 993kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 1.0MB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.0MB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.0MB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.0MB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 1.0MB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.1MB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.1MB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.1MB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.1MB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.1MB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.1MB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.1MB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.1MB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.1MB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.1MB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.2MB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.2MB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.2MB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.2MB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.2MB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.2MB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.2MB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.2MB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.2MB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.2MB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.3MB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.3MB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.3MB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.3MB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.3MB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.3MB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.3MB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.3MB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.3MB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.4MB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.4MB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.4MB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.4MB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.4MB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.4MB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.4MB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.4MB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.4MB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.4MB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.5MB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.5MB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.5MB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.5MB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.5MB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.5MB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.5MB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.5MB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.5MB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.5MB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.6MB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.6MB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.6MB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.6MB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.6MB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.6MB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.6MB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.6MB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.6MB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.6MB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.7MB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.7MB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.7MB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.7MB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.7MB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.7MB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.7MB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.7MB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.7MB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.8MB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.8MB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.8MB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.8MB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.8MB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.8MB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.8MB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.8MB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.8MB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.8MB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.9MB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.9MB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.9MB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.9MB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.9MB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.9MB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.9MB 9.7MB/s \n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.5.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhapVesNcB8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from spellchecker import SpellChecker\n",
        "\n",
        "spell = SpellChecker()\n",
        "def correct_spellings(text):\n",
        "    corrected_text = []\n",
        "    misspelled_words = spell.unknown(text.split())\n",
        "    for word in text.split():\n",
        "        if word in misspelled_words:\n",
        "            corrected_text.append(spell.correction(word))\n",
        "        else:\n",
        "            corrected_text.append(word)\n",
        "    return \" \".join(corrected_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLi6XzODcDt6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "outputId": "e0e5cfcd-e9cf-4ae1-f63a-af8f6c3a0cd8"
      },
      "source": [
        "#df_Train['text']=df_Train['text'].apply(lambda x : correct_spellings(x))\n",
        "#df_Test['text']=df_Test['text'].apply(lambda x : correct_spellings(x))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-7e2b00a27c8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_Train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_Train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mcorrect_spellings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_Test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_Test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mcorrect_spellings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3847\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3848\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-7e2b00a27c8d>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_Train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_Train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mcorrect_spellings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_Test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_Test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mcorrect_spellings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-edc0c0f9b04c>\u001b[0m in \u001b[0;36mcorrect_spellings\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmisspelled_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mcorrected_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mcorrected_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spellchecker/spellchecker.py\u001b[0m in \u001b[0;36mcorrection\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    146\u001b[0m                 str: The most likely candidate \"\"\"\n\u001b[1;32m    147\u001b[0m         \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mENSURE_UNICODE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mcandidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_probability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spellchecker/spellchecker.py\u001b[0m in \u001b[0;36mcandidates\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;31m# if still not found, use the edit distance 1 to calc edit distance 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distance\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mknown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__edit_distance_alt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spellchecker/spellchecker.py\u001b[0m in \u001b[0;36m__edit_distance_alt\u001b[0;34m(self, words)\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_if_should_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         ]\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0me2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mknown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medit_distance_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_if_should_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spellchecker/spellchecker.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_if_should_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         ]\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0me2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mknown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medit_distance_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_if_should_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spellchecker/spellchecker.py\u001b[0m in \u001b[0;36medit_distance_1\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mdeletes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mL\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplits\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mtransposes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mL\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplits\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mreplaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mL\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplits\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mR\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mletters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0minserts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mL\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mR\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplits\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mletters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeletes\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtransposes\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreplaces\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minserts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spellchecker/spellchecker.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mdeletes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mL\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplits\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mtransposes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mL\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplits\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mreplaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mL\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplits\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mR\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mletters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0minserts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mL\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mR\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplits\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mletters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeletes\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtransposes\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreplaces\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minserts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGWBcVjtnAXy",
        "colab_type": "text"
      },
      "source": [
        "### Convert to Lower Case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXi5tfqPcZs7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lowercase_text = [word.lower() for word in text.split()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V72VnjQhnY-I",
        "colab_type": "text"
      },
      "source": [
        "### Remove Numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RD520LcnbkB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_numbers(text):\n",
        "    text = ''.join([i for i in text if not i.isdigit()])         \n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wffHTP3Rnf8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_Train['text'] = df_Train['text'].apply(lambda x : remove_numbers(x))\n",
        "df_Test['text'] = df_Test['text'].apply(lambda x : remove_numbers(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X0yhyzCnoTR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "e58defc2-3596-46ee-8b24-7e875ee8a182"
      },
      "source": [
        "df_Train['text'].head(15)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      our deeds reason earthquake may allah forgive us\n",
              "1                 forest fire near la ronge sask canada\n",
              "2     all residents ask shelter place notify officer...\n",
              "3      people receive wildfires evacuation order cal...\n",
              "4     just get send photo ruby alaska smoke wildfire...\n",
              "5     rockyfire update california hwy  close directi...\n",
              "6     flood disaster heavy rain cause flash flood st...\n",
              "7                            im top hill see fire woods\n",
              "8     theres emergency evacuation happen build acros...\n",
              "9                           im afraid tornado come area\n",
              "10                       three people die heat wave far\n",
              "11    haha south tampa get flood hah wait second liv...\n",
              "12    rain flood florida tampabay tampa   days ive l...\n",
              "13                    flood bago myanmar we arrive bago\n",
              "14             damage school bus  multi car crash break\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRW24ZSmnrub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}